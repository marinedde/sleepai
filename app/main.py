"""
API FastAPI pour la classification de stades de sommeil.

Cette API expose le mod√®le SleepAI via des endpoints REST.
"""

from fastapi import FastAPI, HTTPException, status
from fastapi.middleware.cors import CORSMiddleware
from contextlib import asynccontextmanager
from pathlib import Path
import numpy as np
import logging

from app.models import (
    PredictionRequest,
    PredictionResponse,
    HealthResponse,
    ModelInfoResponse
)
from app.ml_model import SleepStageClassifier

# Configuration du logging
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

# Variable globale pour le mod√®le (sera initialis√©e au startup)
model: SleepStageClassifier = None

# Chemin absolu du mod√®le
PROJECT_ROOT = Path(__file__).parent.parent  # Remonte de app/ vers sleepai/
MODEL_PATH = PROJECT_ROOT / "notebooks" / "models" / "rf_v2_pipeline_fixed.joblib"


@asynccontextmanager
async def lifespan(app: FastAPI):
    """
    Gestionnaire de cycle de vie de l'application.
    
    - startup: Charge le mod√®le au d√©marrage
    - shutdown: Nettoyage (si n√©cessaire)
    """
    # Startup: Charger le mod√®le
    global model
    logger.info("üöÄ D√©marrage de l'API SleepAI...")
    logger.info(f"üìÇ Chemin du mod√®le : {MODEL_PATH}")
    
    try:
        model = SleepStageClassifier(model_path=str(MODEL_PATH))
        logger.info("‚úÖ Mod√®le charg√© avec succ√®s")
    except Exception as e:
        logger.error(f"‚ùå Erreur au chargement du mod√®le: {e}")
        raise
    
    yield  # L'API tourne ici
    
    # Shutdown: Nettoyage
    logger.info("üõë Arr√™t de l'API SleepAI...")


# Cr√©er l'application FastAPI
app = FastAPI(
    title="SleepAI API",
    description="""
    API de classification automatique de stades de sommeil √† partir de signaux EEG.
    
    ## Fonctionnalit√©s
    
    * **Pr√©diction** : Classifie un signal EEG en 5 stades (Wake, N1, N2, N3, REM)
    * **Monitoring** : Endpoints de sant√© et d'information sur le mod√®le
    
    ## Utilisation
    
    Envoyez un signal EEG de 30 secondes (3000 points √† 100Hz) au endpoint `/predict`.
    """,
    version="1.0.0",
    lifespan=lifespan
)

# Configuration CORS (pour autoriser les requ√™tes depuis un frontend)
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],  # En production: sp√©cifier les domaines autoris√©s
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)


@app.get("/", tags=["Root"])
async def root():
    """
    Endpoint racine.
    
    Retourne un message de bienvenue et les endpoints disponibles.
    """
    return {
        "message": "Bienvenue sur l'API SleepAI üåô",
        "version": "1.0.0",
        "endpoints": {
            "prediction": "/predict",
            "health": "/health",
            "model_info": "/model-info",
            "documentation": "/docs"
        }
    }


@app.get("/health", response_model=HealthResponse, tags=["Monitoring"])
async def health_check():
    """
    V√©rifie l'√©tat de sant√© de l'API.
    
    Retourne:
    - status: "healthy" ou "unhealthy"
    - model_loaded: True si le mod√®le est charg√©
    - model_path: Chemin du mod√®le
    """
    is_healthy = model is not None and model.is_loaded()
    
    return HealthResponse(
        status="healthy" if is_healthy else "unhealthy",
        model_loaded=is_healthy,
        model_path=str(model.model_path) if model else "N/A"
    )


@app.get("/model-info", response_model=ModelInfoResponse, tags=["Monitoring"])
async def get_model_info():
    """
    Retourne les informations sur le mod√®le charg√©.
    
    Inclut:
    - Type de mod√®le
    - M√©triques de performance (accuracy, F1-score, etc.)
    - Classes pr√©dites
    - Nombre de features
    """
    if model is None or not model.is_loaded():
        raise HTTPException(
            status_code=status.HTTP_503_SERVICE_UNAVAILABLE,
            detail="Mod√®le non charg√©"
        )
    
    return ModelInfoResponse(**model.get_model_info())


@app.post("/predict", response_model=PredictionResponse, tags=["Prediction"])
async def predict_sleep_stage(request: PredictionRequest):
    """
    Pr√©dit le stade de sommeil √† partir d'un signal EEG.
    
    ## Input
    
    - **signal**: Liste de 3000 valeurs num√©riques (30s √† 100Hz)
    
    ## Output
    
    - **predicted_class**: Stade de sommeil pr√©dit (Wake, N1, N2, N3, REM)
    - **predicted_index**: Index de la classe (0-4)
    - **confidence**: Confiance de la pr√©diction (0-1)
    - **probabilities**: Probabilit√©s pour chaque classe
    
    ## Exemple
```python
    import requests
    
    signal = [0.5, -0.2, 1.3, ...] # 3000 valeurs
    response = requests.post("http://localhost:8000/predict", json={"signal": signal})
    print(response.json())
```
    """
    # V√©rifier que le mod√®le est charg√©
    if model is None or not model.is_loaded():
        raise HTTPException(
            status_code=status.HTTP_503_SERVICE_UNAVAILABLE,
            detail="Mod√®le non charg√©. Veuillez red√©marrer le serveur."
        )
    
    try:
        # Convertir la liste en array numpy
        signal_array = np.array(request.signal).reshape(1, -1)
        
        # Faire la pr√©diction
        predicted_class, predicted_index, confidence, probabilities = model.predict(signal_array)
        
        # Retourner la r√©ponse
        return PredictionResponse(
            predicted_class=predicted_class,
            predicted_index=predicted_index,
            confidence=confidence,
            probabilities=probabilities
        )
        
    except ValueError as e:
        # Erreur de validation du signal
        raise HTTPException(
            status_code=status.HTTP_400_BAD_REQUEST,
            detail=f"Signal invalide: {str(e)}"
        )
    except Exception as e:
        # Erreur interne
        logger.error(f"Erreur lors de la pr√©diction: {e}")
        raise HTTPException(
            status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
            detail=f"Erreur interne: {str(e)}"
        )


# Pour ex√©cuter en mode d√©veloppement
if __name__ == "__main__":
    import uvicorn
    uvicorn.run(app, host="0.0.0.0", port=8000)